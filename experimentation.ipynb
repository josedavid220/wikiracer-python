{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c31f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_wikiracer.internet import Internet\n",
    "from py_wikiracer.wikiracer import Parser, DijkstrasProblem, WikiracerProblem\n",
    "import re\n",
    "import heapq\n",
    "import Levenshtein\n",
    "import sys\n",
    "import random\n",
    "import sys\n",
    "from typing import Callable, Iterator\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from types import ModuleType\n",
    "from importlib import reload\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d973704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Main_Page',\n",
       " '/wiki/Henry_Krumrey',\n",
       " '/wiki/Wisconsin_State_Senate',\n",
       " '/wiki/Wisconsin_Senate,_District_20',\n",
       " '/wiki/Wisconsin_State_Assembly',\n",
       " '/wiki/Plymouth,_Sheboygan_County,_Wisconsin',\n",
       " '/wiki/Republican_Party_(United_States)',\n",
       " '/wiki/Sheboygan_County,_Wisconsin',\n",
       " '/wiki/United_States_presidential_election_in_Wisconsin,_1900',\n",
       " '/wiki/Farmers%27_suicides_in_the_United_States',\n",
       " '/wiki/Crystal_Lake,_Illinois']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internet = Internet()\n",
    "html = internet.get_page(\"/wiki/Henry_Krumrey\")\n",
    "result = Parser.get_links_in_page(html)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "275e1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parser():\n",
    "    internet = Internet()\n",
    "    html = internet.get_page(\"/wiki/Henry_Krumrey\")\n",
    "    assert Parser.get_links_in_page(html) == ['/wiki/Main_Page',\n",
    "                                             '/wiki/Henry_Krumrey',\n",
    "                                             '/wiki/Wisconsin_State_Senate',\n",
    "                                             '/wiki/Wisconsin_Senate,_District_20',\n",
    "                                             '/wiki/Wisconsin_State_Assembly',\n",
    "                                             '/wiki/Plymouth,_Sheboygan_County,_Wisconsin',\n",
    "                                             '/wiki/Republican_Party_(United_States)',\n",
    "                                             '/wiki/Sheboygan_County,_Wisconsin',\n",
    "                                             '/wiki/United_States_presidential_election_in_Wisconsin,_1900',\n",
    "                                             '/wiki/Farmers%27_suicides_in_the_United_States',\n",
    "                                             '/wiki/Crystal_Lake,_Illinois']\n",
    "    \n",
    "test_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "285c1766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/ASDF', '/wiki/ASDF']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DijkstrasProblem:\n",
    "    def __init__(self):\n",
    "        self.internet = Internet()\n",
    "        self.parser = Parser()\n",
    "\n",
    "    def dijkstras(\n",
    "        self,\n",
    "        source=\"/wiki/Calvin_Li\",\n",
    "        goal=\"/wiki/Wikipedia\",\n",
    "        costFn=lambda x, y: len(y),\n",
    "    ):\n",
    "        path = []\n",
    "        distances = {source: 0}\n",
    "        priority_queue = [(0, source)]  # (distance, link)\n",
    "\n",
    "        # Dictionary to store the predecessor of each link\n",
    "        predecessors = {source: None}\n",
    "\n",
    "        while priority_queue:\n",
    "            current_distance, current_link = heapq.heappop(priority_queue)\n",
    "\n",
    "            # If the extracted distance is greater than the known shortest, skip\n",
    "            if current_distance > distances[current_link]:\n",
    "                continue\n",
    "\n",
    "            current_link_html = self.internet.get_page(current_link)\n",
    "            neighbor_links = self.parser.get_links_in_page(current_link_html)\n",
    "\n",
    "            for neighbor_link in neighbor_links:\n",
    "                if neighbor_link not in distances:\n",
    "                    distances[neighbor_link] = float(\"infinity\")\n",
    "                    predecessors[neighbor_link] = None\n",
    "\n",
    "                weight = costFn(current_link, neighbor_link)\n",
    "                distance = current_distance + weight\n",
    "\n",
    "                # If a shorter path to the neighbor is found, update and push to queue\n",
    "                if distance < distances[neighbor_link]:\n",
    "                    distances[neighbor_link] = distance\n",
    "                    predecessors[neighbor_link] = current_link\n",
    "                    heapq.heappush(priority_queue, (distance, neighbor_link))\n",
    "\n",
    "            # If we reached the target, reconstruct and return the path\n",
    "            if goal in neighbor_links:\n",
    "                neighbor_link = goal\n",
    "                while neighbor_link is not None:\n",
    "                    path.insert(0, neighbor_link)\n",
    "                    neighbor_link = predecessors[neighbor_link]\n",
    "\n",
    "                if source == goal:\n",
    "                    path.append(goal)\n",
    "                return path\n",
    "        \n",
    "        # If the loop finishes without finding the goal\n",
    "        return None\n",
    "\n",
    "dij = DijkstrasProblem()\n",
    "dij.dijkstras(source = \"/wiki/ASDF\", goal = \"/wiki/ASDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4cd47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trivial():\n",
    "    \"\"\"\n",
    "    All pages contain a link to themselves, which any search algorithm should recognize.\n",
    "    \"\"\"\n",
    "    dij = DijkstrasProblem()\n",
    "\n",
    "    assert dij.dijkstras(source=\"/wiki/ASDF\", goal=\"/wiki/ASDF\") == [\n",
    "        \"/wiki/ASDF\",\n",
    "        \"/wiki/ASDF\",\n",
    "    ]\n",
    "    assert dij.internet.requests == [\"/wiki/ASDF\"]\n",
    "\n",
    "\n",
    "def test_trivial_2():\n",
    "    \"\"\"\n",
    "    Searches going to page 1 distance away.\n",
    "    \"\"\"\n",
    "    dij = DijkstrasProblem()\n",
    "\n",
    "    assert dij.dijkstras(\n",
    "        source=\"/wiki/Reese_Witherspoon\", goal=\"/wiki/Academy_Awards\"\n",
    "    ) == [\"/wiki/Reese_Witherspoon\", \"/wiki/Academy_Awards\"]\n",
    "    assert dij.internet.requests == [\"/wiki/Reese_Witherspoon\"]\n",
    "\n",
    "\n",
    "def test_dijkstras_basic():\n",
    "    \"\"\"\n",
    "    DFS depth 2 search\n",
    "    \"\"\"\n",
    "    dij = DijkstrasProblem()\n",
    "    # This costFn is to make sure there are never any ties coming out of the heap, since the default costFn produces ties and we don't define a tiebreaking mechanism for priorities\n",
    "    assert dij.dijkstras(\n",
    "        source=\"/wiki/Calvin_Li\",\n",
    "        goal=\"/wiki/Wikipedia\",\n",
    "        costFn=lambda y, x: len(x) * 1000\n",
    "        + x.count(\"a\") * 100\n",
    "        + x.count(\"u\")\n",
    "        + x.count(\"h\") * 5\n",
    "        - x.count(\"F\"),\n",
    "    ) == [\"/wiki/Calvin_Li\", \"/wiki/Main_Page\", \"/wiki/Wikipedia\"]\n",
    "    assert dij.internet.requests == [\n",
    "        \"/wiki/Calvin_Li\",\n",
    "        \"/wiki/Weibo\",\n",
    "        \"/wiki/Hubei\",\n",
    "        \"/wiki/Wuxia\",\n",
    "        \"/wiki/Wuhan\",\n",
    "        \"/wiki/Pinyin\",\n",
    "        \"/wiki/Tencent\",\n",
    "        \"/wiki/Wu_Yong\",\n",
    "        \"/wiki/Cao_Cao\",\n",
    "        \"/wiki/John_Woo\",\n",
    "        \"/wiki/Kelly_Lin\",\n",
    "        \"/wiki/Sina_Corp\",\n",
    "        \"/wiki/Huo_Siyan\",\n",
    "        \"/wiki/Shawn_Yue\",\n",
    "        \"/wiki/Main_Page\",\n",
    "    ]\n",
    "    \n",
    "class CustomInternet():\n",
    "    def __init__(self):\n",
    "        self.requests = []\n",
    "    def get_page(self, page):\n",
    "        self.requests.append(page)\n",
    "        return f'<a href=\"{page}\"></a>'\n",
    "\n",
    "\n",
    "def test_none_on_fail():\n",
    "    \"\"\"\n",
    "    Program should return None on failure\n",
    "    \"\"\"\n",
    "    dij = DijkstrasProblem()\n",
    "\n",
    "    # Testing hack: override the internet to inject our own HTML\n",
    "    dij.internet = CustomInternet()\n",
    "\n",
    "    assert dij.dijkstras(source = \"/wiki/Calvin_Li\", goal = \"/wiki/Wikipedia\") == None\n",
    "    assert dij.internet.requests == [\"/wiki/Calvin_Li\"]\n",
    "\n",
    "test_trivial()\n",
    "test_trivial_2()\n",
    "test_dijkstras_basic()\n",
    "test_none_on_fail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df17736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/wiki/ASDF', '/wiki/ASDF']\n",
      "1\n",
      "['/wiki/Computer_science', '/wiki/IBM', '/wiki/General_Electric', '/wiki/General_Comprehensive_Operating_System', '/wiki/Richard_Soley']\n",
      "['/wiki/Computer_science', '/wiki/IBM', '/wiki/General_Electric', '/wiki/General_Comprehensive_Operating_System']\n",
      "4\n",
      "\n",
      " ['/wiki/Waakirchen', '/wiki/Main_Page', '/wiki/English_language', '/wiki/%C3%86', '/wiki/A']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "class WikiracerProblem:\n",
    "    def __init__(self):\n",
    "        self.internet = Internet()\n",
    "        self.parser = Parser()\n",
    "    \n",
    "    def costFn(self, current_link, neighbor_link, goal_links, goal):\n",
    "        MAX_PRIORITY_SCORE = 0\n",
    "        \n",
    "        # Check if the neighbor link is contained in the links\n",
    "        # of the goal, hoping there is a bidirectional connection\n",
    "        if neighbor_link in goal_links:\n",
    "            return MAX_PRIORITY_SCORE\n",
    "        \n",
    "        # NOTE: This doesn't add value! It is a weaker version of the Levenshtein distance\n",
    "        # # Check if a neighbor link is a substring or a superstring of the goal link\n",
    "        # # Exclude neighbors that don't add information, like '/wiki/A'\n",
    "        # wikiless_goal = goal[6:]\n",
    "        # wikiless_neighbor = neighbor_link[6:]\n",
    "        # min_wiki_length = 2\n",
    "        # if len(wikiless_neighbor) > min_wiki_length and len(wikiless_goal) > min_wiki_length :\n",
    "        #     # goal_lower = goal.lower()\n",
    "        #     # neighbor_link_lower = neighbor_link.lower()\n",
    "        #     neighbor_is_substr = wikiless_goal.find(wikiless_neighbor) != -1\n",
    "        #     neighbor_is_supstr = wikiless_neighbor.find(wikiless_goal) != -1\n",
    "            \n",
    "        #     # Proritize neighbors with any of the previous properties\n",
    "        #     if neighbor_is_substr or neighbor_is_supstr:\n",
    "        #         return MAX_PRIORITY_SCORE\n",
    "        \n",
    "        return Levenshtein.distance(neighbor_link, goal)\n",
    "\n",
    "    def wikiracer(self, source=\"/wiki/Calvin_Li\", goal=\"/wiki/Wikipedia\"):\n",
    "        path = []\n",
    "        distances = {source: 0}\n",
    "        priority_queue = [(0, source)]  # (distance, link)\n",
    "        goal_html = self.internet.get_page(goal)\n",
    "        \n",
    "        goal_links = self.parser.get_links_in_page(goal_html)\n",
    "        self.internet.requests.clear() # To prevent validation errors in tests\n",
    "\n",
    "        # Dictionary to store the predecessor of each link\n",
    "        predecessors = {source: None}\n",
    "\n",
    "        while priority_queue:\n",
    "            current_distance, current_link = heapq.heappop(priority_queue)\n",
    "\n",
    "            # If the extracted distance is greater than the known shortest, skip\n",
    "            if current_distance > distances[current_link]:\n",
    "                continue\n",
    "\n",
    "            current_link_html = self.internet.get_page(current_link)\n",
    "            neighbor_links = self.parser.get_links_in_page(current_link_html)\n",
    "\n",
    "            for neighbor_link in neighbor_links:\n",
    "                if neighbor_link not in distances:\n",
    "                    distances[neighbor_link] = float(\"infinity\")\n",
    "                    predecessors[neighbor_link] = None\n",
    "\n",
    "                weight = self.costFn(current_link, neighbor_link, goal_links=goal_links, goal=goal)\n",
    "                distance = current_distance + weight\n",
    "\n",
    "                # If a shorter path to the neighbor is found, update and push to queue\n",
    "                if distance < distances[neighbor_link]:\n",
    "                    distances[neighbor_link] = distance\n",
    "                    predecessors[neighbor_link] = current_link\n",
    "                    heapq.heappush(priority_queue, (distance, neighbor_link))\n",
    "\n",
    "            # If we reached the target, reconstruct and return the path\n",
    "            if goal in neighbor_links:\n",
    "                neighbor_link = goal\n",
    "                while neighbor_link is not None:\n",
    "                    path.insert(0, neighbor_link)\n",
    "                    neighbor_link = predecessors[neighbor_link]\n",
    "\n",
    "                if source == goal:\n",
    "                    path.append(goal)\n",
    "                return path\n",
    "        \n",
    "        # If the loop finishes without finding the goal\n",
    "        return None\n",
    "\n",
    "def test_trivial():\n",
    "    \"\"\"\n",
    "    All pages contain a link to themselves, which any search algorithm should recognize.\n",
    "    \"\"\"\n",
    "    wiki_racer = WikiracerProblem()\n",
    "\n",
    "    path = wiki_racer.wikiracer(source=\"/wiki/ASDF\", goal=\"/wiki/ASDF\")\n",
    "    print(path)\n",
    "    print(len(wiki_racer.internet.requests))\n",
    "    \n",
    "    assert  path == [\n",
    "        \"/wiki/ASDF\",\n",
    "        \"/wiki/ASDF\",\n",
    "    ]\n",
    "    assert wiki_racer.internet.requests == [\"/wiki/ASDF\"]\n",
    "    \n",
    "def test_wikiracer_1():\n",
    "    limit = 15\n",
    "\n",
    "    racer = WikiracerProblem()\n",
    "    path = racer.wikiracer(source=\"/wiki/Computer_science\", goal=\"/wiki/Richard_Soley\")\n",
    "    print(path)\n",
    "    print(racer.internet.requests)\n",
    "    print(len(racer.internet.requests))\n",
    "    assert len(racer.internet.requests) <= limit\n",
    "    \n",
    "def test_wikiracer_2():\n",
    "    limit = 80\n",
    "\n",
    "    racer = WikiracerProblem()\n",
    "    path = racer.wikiracer(source=\"/wiki/Waakirchen\", goal=\"/wiki/A\")\n",
    "    print(\"\\n\", path)\n",
    "    print(len(racer.internet.requests))\n",
    "    assert len(racer.internet.requests) <= limit\n",
    "\n",
    "def test_wikiracer_multiple():\n",
    "    '''\n",
    "    Tests wikiracer on multiple websites.\n",
    "    Does a combination of all links and calls wikiracer to tests those combinations.\n",
    "    This also tests that the path between pages is actually navigable\n",
    "    Beware: This function test take long time to run. You can change to a smaller list to verify\n",
    "    that your algorithm works.\n",
    "    The default test takes around 5-10 minutes when the pages are not cached.\n",
    "    '''\n",
    "    pages = ['Jesus', 'Adolf_Hitler', 'Michael_Jordan', 'United_Nations', 'Kobe_Bryant', 'Brazil']\n",
    "\n",
    "    allCombinations = list(combinations(pages, 2))\n",
    "    paths = []\n",
    "    with open(\"../results.txt\", \"w\") as results:\n",
    "        for combination in allCombinations:\n",
    "            racer = WikiracerProblem()\n",
    "            paths.append(racer.wikiracer(source=r'/wiki/' + combination[0], goal=r'/wiki/' + combination[1]))\n",
    "            results.write(f\"{combination} {len(racer.internet.requests)}\\n\")\n",
    "\n",
    "        for i, path in enumerate(paths):\n",
    "            results.write(f\"\\n####### {i} #######\\n\")\n",
    "            source = path.pop(0)\n",
    "            results.write(f\"{source}\\n\")\n",
    "            while len(path) > 0:\n",
    "                destination = path.pop(0)\n",
    "                results.write(f\"{destination}\\n\")\n",
    "                links = Parser.get_links_in_page(Internet().get_page(source))\n",
    "                assert destination in links\n",
    "                source = destination\n",
    "            results.write(f\"#################\\n\")\n",
    "\n",
    "test_trivial()\n",
    "test_wikiracer_1()\n",
    "test_wikiracer_2()\n",
    "# test_wikiracer_multiple()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09e66c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest distance from A to D: 4\n",
      "Shortest path: A -> B -> C -> D\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "def dijkstra(graph, start, end):\n",
    "    # Priority queue stores tuples of (distance, node)\n",
    "    priority_queue = [(0, start)]\n",
    "    \n",
    "    # Dictionary to store the shortest distance found so far\n",
    "    distances = {node: float('inf') for node in graph}\n",
    "    distances[start] = 0\n",
    "    \n",
    "    # Dictionary to store the predecessor of each node\n",
    "    predecessors = {node: None for node in graph}\n",
    "\n",
    "    while priority_queue:\n",
    "        current_distance, current_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        # If we reached the target, reconstruct and return the path\n",
    "        if current_node == end:\n",
    "            path = []\n",
    "            node = end\n",
    "            while node is not None:\n",
    "                path.insert(0, node)\n",
    "                node = predecessors[node]\n",
    "            return distances[end], path\n",
    "\n",
    "        # If the extracted distance is greater than the known shortest, skip\n",
    "        if current_distance > distances[current_node]:\n",
    "            continue\n",
    "\n",
    "        for neighbor, weight in graph[current_node].items():\n",
    "            distance = current_distance + weight\n",
    "            \n",
    "            # If a shorter path to the neighbor is found, update and push to queue\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                predecessors[neighbor] = current_node\n",
    "                heapq.heappush(priority_queue, (distance, neighbor))\n",
    "\n",
    "    # If the loop finishes without finding the destination\n",
    "    return float('inf'), None\n",
    "\n",
    "graph = {\n",
    "    'A': {'B': 1, 'C': 4},\n",
    "    'B': {'A': 1, 'C': 2, 'D': 5},\n",
    "    'C': {'A': 4, 'B': 2, 'D': 1},\n",
    "    'D': {'B': 5, 'C': 1}\n",
    "}\n",
    "\n",
    "start_node = 'A'\n",
    "end_node = 'D'\n",
    "\n",
    "dijkstra(graph, start_node, end_node)\n",
    "shortest_distance, shortest_path = dijkstra(graph, start_node, end_node)\n",
    "\n",
    "if shortest_path:\n",
    "    print(f\"Shortest distance from {start_node} to {end_node}: {shortest_distance}\")\n",
    "    print(f\"Shortest path: {' -> '.join(shortest_path)}\")\n",
    "else:\n",
    "    print(f\"No path found from {start_node} to {end_node}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikiracer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
